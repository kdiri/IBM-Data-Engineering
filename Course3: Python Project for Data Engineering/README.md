   * [Course Introduction](#course-introduction)
   * [Project Overview](#project-overview)
   * [Scenario](#scenario)
   * [Project Tasks](#project-tasks)



## Course Introduction

Welcome to this Python Project!  

**This mini-course is intended to be a follow-on to the** [**Python for Data Science, AI and Development**](https://www.coursera.org/learn/python-for-applied-data-science-ai) **course for you to demonstrate basic Python skills that you have acquired in that course.**

In this mini-course you will be assuming the role of a Data Engineer. In this role you will be given a scenario and data set to begin your Python code creation. During this process you will perform specific tasks such as extracting data from different file formats, collecting data through APIs and webscraping and finally transforming the collected data into a ready-to-load format. You will then submit your Python notebook and screenshots for your peers to review and evaluate your work.

To be successful in completing this project, you should have already completed the [Python for Data Science, AI and Development](https://www.coursera.org/learn/python-for-applied-data-science-ai) course or have equivalent skills for working with Data and Python.


## Project Overview

## Scenario

For this project, you will assume the role of data engineer working for an international financial analysis company. Your company tracks stock prices, commodities, forex rates, inflation rates.  Your job is to extract financial data from various sources like websites, APIs and files provided by various financial analysis firms. After you collect the data, you extract the data of interest to your company and transform it based on the requirements given to you. Once the transformation is complete you load that data into a database.

## Project Tasks

In this project you will:

- Collect data using APIs
- Collect data using webscraping.
- Download files to process.    
- Read csv, xml and json file types.
- Extract data from the above file types.
- Transform data.
- Use the built in logging module.
- Save the transformed data in a ready-to-load format which data engineers can use to load the data.
